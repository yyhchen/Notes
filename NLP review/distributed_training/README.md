# 分布式训练


---



## 1. 分布式训练

### 1.1. 概述

- **分布式训练**：将一个任务拆分成多个子任务，由多个计算节点并行执行，从而提高训练效率。
- 分布式训练的**两种方式**：
  - 数据并行：将数据拆分成多个部分，每个计算节点处理一部分数据，然后将结果汇总。
  - 模型并行：将模型拆分成多个部分，每个计算节点处理一部分模型，然后将结果汇总。

### 1.2. 数据并行 （Data Parallel, DP）
- **数据并行**：将**数据**拆分成多个部分，每个计算节点处理一部分**数据**，然后将结果汇总。
    - 每个GPU都复制一份完整的模型，但是每个GPU上训练的数据不同
    - 要求每张卡内都可以完整执行训练过程（！！）

![DP-hand](/NLP%20review/assets/DP-hand.png)

更细节的如下图所示：

![DP](/NLP%20review/assets/DP_detail.png)


<br>
<br>


### 1.3 流水并行 (Pipeline Parallell, PP)

- **流水并行**：将**模型**拆分成多个部分，每个计算节点处理一部分**模型**，然后将结果汇总。
    - 将**模型**按层拆开，每个GPU上包含部分层，保证能够正常训练
    - **不要求**每张卡内可以完整执行训练过程（！！） 

![PP-hand](/NLP%20review/assets/PP-hand.png)

更细节的如下图所示：

![PP](/NLP%20review/assets/PP_detail.png)

<br>
<br>


### 1.4 张量并行 （Tensor Parallel）
- **张量并行**：将**模型参数**拆分成多个部分，每个计算节点处理一部分**模型参数**。
    - 将**模型参数**按维度拆开，每个GPU上包含部分参数，保证能够正常训练
    - **不要求**每张卡内可以完整执行训练过程（！！） 

![TP-hand](/NLP%20review/assets/TP_hand.png)

更细节的如下图所示：

![TP](/NLP%20review/assets/TP_detail.png)

<br>
<br>


### 1.5 混合并行策略

数据并行 + 流水并行 + 张量并行 (3D并行)

如图所示：

![3d parallel](/NLP%20review/assets/3D_parallel.png)