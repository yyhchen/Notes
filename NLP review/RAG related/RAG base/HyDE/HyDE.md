# HyDE 虚拟文档嵌入(Hypothetical Document Embedder)


---


![alt text](image.png)

这个笔记本介绍了如何使用虚拟文档嵌入（HyDE），如 [Precise Zero-Shot Dense Retrieval without Relevance Labels](https://arxiv.org/abs/2212.10496) 所述。

在高层次上，HyDE是一种嵌入技术，它接受查询，生成一个虚拟答案，然后嵌入该生成的文档并将其用作最终示例。

为了使用HyDE，我们需要提供一个基本的嵌入模型，以及一个用于生成这些文档的LLMChain。默认情况下，HyDE类带有一些默认的提示（有关详细信息，请参阅论文），但我们也可以创建自己的提示。


- [langchain 文档提到的 HyDE](https://python.langchain.com.cn/docs/modules/chains/additional/hyde)


<br>
<br>
<br>


### HyDE paper 涉及到的内容
这篇论文提出了一个新的无监督密集检索模型HyDE，其主要思路如下：
1. **无监督检索难点**：密集检索需要学习查询和文档的语义表示，并计算它们之间的相似度。无监督情况下，无法获得相关文档的监督信号，这使得表示学习变得困难。
2. **HyDE模型**：作者将检索分解为两个子任务。**首先**，利用指令遵循的语言模型，根据查询生成一个假设的文档。**然后**，利用无监督对比学习的编码器，将假设文档编码为向量表示。这个向量用于在语料库中搜索最相似的文档。
3. **实现**：具体来说，作者使用InstructGPT生成假设文档，并使用Contriever编码假设文档。生成的文档虽然可能包含错误细节，但能捕捉相关性。Contriever的密集瓶颈结构可以过滤错误细节。
4. **实验结果**：在11个查询集上，HyDE在web搜索、问答、事实核查等任务上均优于仅使用Contriever的基线系统。与微调后的检索系统相比，HyDE也展现出较强性能。
5. **分析**：作者分析了不同生成模型和微调编码器的影响。发现更大规模的生成模型效果更好，而微调编码器对HyDE影响较小。
6. **结论**：该论文提出了利用生成模型和编码器实现无监督密集检索的新思路，并证明了其有效性。为无需相关监督的密集检索系统提供了有效途径。


<br>


#### 什么是Contriever?
Contriever是一种通过无监督对比学习训练的文本编码器，旨在学习文本之间的语义表示，使其在向量空间中能够反映文本内容的相关性。具体来说，Contriever的训练不依赖于人工标注的相关性数据，而是利用大规模文本语料库进行自监督训练。**在训练过程中，Contriever将每个文本编码为固定维度的向量，并通过对比学习的方式学习文本表示，即拉近正样本对的表示并推开负样本对的表示**。通过这种方式，Contriever学习到可以反映文本语义相关性的表示。Contriever的名称来源于其结合了Contrastive和Retrieval两个概念，旨在通过对比学习的方式学习文本表示，以支持检索任务。在本文中，Contriever编码器被应用于HyDE模型中，利用其学习到的文本表示进行无监督的文档检索。
(补充： 参考文章：[Unsupervised Dense Information Retrieval with Contrastive Learning](https://arxiv.org/abs/2112.09118))


<br>
<br>
<br>

### TF-IDF（常用的传统文档检索方法）
TF-IDF（Term Frequency-Inverse Document Frequency）是一种常用的文本表示方法，用于评估一个词在文本中的重要程度。其基本思想是，如果一个词在文本中出现的频率（TF）高，同时在其他文本中出现频率（IDF）低，那么这个词可以视为文本的一个重要特征。
具体来说，TF-IDF的计算方式如下：
1. **Term Frequency (TF)**：计算一个词在文本中出现的次数，并除以文本中的总词数，以反映该词在文本中的相对重要性。
2. **Inverse Document Frequency (IDF)**：计算一个词在所有文本中出现的频率的倒数，以反映该词在文本中的区分性。
3. **TF-IDF**：将TF和IDF相乘，得到一个词的TF-IDF分数，这个分数可以反映一个词在特定文本中的重要性。
TF-IDF在文本检索和信息检索系统中被广泛使用，它能够突出文档的关键词，提高检索效果。同时，TF-IDF也可以用于文本挖掘、关键词提取和文本分类等领域。相比其他词嵌入方法，TF-IDF更简单高效，且不需要大规模训练数据。


#### 局限性
TF-IDF作为文本表示的一种方法，虽然具有简单高效的优势，但也存在一些局限性：
1. **无法处理同义词和反义词**：TF-IDF主要依赖词汇的词频信息，无法有效表达词汇之间的语义关系，如同义词和反义词。
2. **忽视词顺序**：TF-IDF无法反映词汇在文本中的顺序关系，可能会遗漏一些有用的信息。
3. **词义不区分**：一个词可能有多个意义，但TF-IDF无法区分不同意义，可能会影响文本表示的准确性。
4. **过度依赖词频**：高词频词汇可能被过度强调，而一些低频但重要的词汇可能被忽略。
5. **难以反映词汇之间的语义关系**：TF-IDF仅基于词频信息，难以反映词汇之间的语义关联。
6. **对噪声敏感**：TF-IDF对噪声敏感，一些常见但无关的停用词可能会被赋予较高的权重。
7. **无法处理生僻词汇**：对于生僻词汇，IDF可能会倾向于赋予较高的权重，但这些词汇可能并不具有区分性。
8. **无法表达词汇的多义性**：TF-IDF无法反映词汇的多义性，可能将不同语义的词汇混淆在一起。
尽管存在这些局限性，TF-IDF在文本检索和信息检索系统中仍然发挥着重要作用，但研究人员也在不断探索更先进的文本表示方法，如词嵌入模型，以克服这些局限性。
