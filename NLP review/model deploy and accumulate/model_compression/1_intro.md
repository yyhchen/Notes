# 模型压缩

---


剪枝、量化、蒸馏与神经架构搜索等模型压缩方法为去除网络冗余提供了有效的解决方案。不同的模型压缩方法的特点如下：

| 方法 | 描述|适用层级 | 是否需要预训练模型  | 优点 | 缺点 |
|----------------|----------|----------|------------------------|------------|------|
| 模型剪枝 | 判断参数、通道、滤波、卷积层的显著性，并剪除不重要的部分|卷积层、全连接层 | 是  | 可以显著减少参数数量，便于在硬件上实现加速；结构化剪枝可以使网络变窄，便于在存储空间与运算速度上实现加速 | 非结构化剪枝会造成网络结构不规整，难以有效加速；结构化剪枝可能会造成与硬件平台不兼容，灵活性差 |
| 模型量化 | 基于权值共享、矩阵近似，减少参数及激活值的存储位数，降低内存开销|卷积层、全连接层 | 是  | 有不错的压缩量和网络性能，训练时间短，可以获得存储量小、计算量低和网络性能好的小型网络 | 量化后的权重和激活降低了网络的容量和特征图的质量，量化到特殊位置时，容易造成预测精度下降，另外会向梯度信息中引入噪声，导致基于梯度下降法的训练过程收敛难度增加 |
| 知识蒸馏 | 将softmax分类器输出作为软知识，作为训练学生网络的先验知识|卷积层、整个网络 | 是  |  训练简单，可以显著减少参数数量，容易与其他压缩方法组合使用实现更大程度压缩 | 网络训练时间长，需要训练教师和学生模型；特殊结构很难与卷积核和较小方向的网络结合使用，泛化性差 |
| 神经网络架构搜索 | 通过搜索算法来探索不同的网络结构，以找到最优的模型配置。|所有层 | 否，从头开始训练 |  能够自动化地发现高性能、资源高效的深度学习模型架构 | 通常需要大量的计算资源和时间，且结果可能受限于搜索空间的定义和搜索算法的选择 |