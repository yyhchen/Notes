# torch 中的 detach

---


```python
# Inference
torch_output = model(torch.from_numpy(input_img)).detach().numpy()
```



这行代码将预处理后的图像数据传递给模型进行推理。`torch.from_numpy(input_img)`将NumPy数组转换为PyTorch张量。模型执行前向传播，并返回一个张量，该张量包含了超分辨率处理后的图像数据。`detach().numpy()`**将张量转换为NumPy数组，并将其从计算图中分离**，以便后续处理。

<br>
<br>

### 为什么将其从计算图中分离,作用是什么

在深度学习框架如PyTorch中，所有的操作都会被记录在一个计算图中。这个计算图是一个有向无环图（DAG），它包含了执行计算所需的所有操作和数据。这个图对于自动微分非常重要，因为它可以追踪数据的变化，从而在训练过程中计算梯度。

当我们对一个张量（tensor）调用`.detach()`方法时，我们实际上是在创建一个新的张量，这个新的张量与原始张量共享数据，但是不与原始张量共享计算图。这意味着，新的张量不再被计算图追踪，它的任何变化都不会影响到原始张量，也不会影响到计算图中的其他部分。

调用`.detach().numpy()`将张量转换为NumPy数组，并**将其从计算图中分离的目的**是为了：

1. **节省内存**：如果张量仍然连接到计算图，那么计算图中的所有中间节点和张量都需要被存储，这会占用大量内存。特别是在处理大型数据集或复杂模型时，这可能导致内存不足。
2. **提高效率**：当张量从计算图中分离后，后续的操作不会影响计算图的结构，这样可以避免不必要的计算和内存使用。
3. **简化操作**：在某些情况下，我们可能只需要使用模型的输出进行一些简单的操作，而不需要进行梯度计算或反向传播。将张量从计算图中分离可以简化这些操作。
4. **避免错误**：在某些情况下，如果后续的操作不是计算图的一部分，那么尝试对这些操作进行梯度计算可能会导致错误。通过分离张量，我们可以避免这些错误。

总的来说，将张量从计算图中分离是一种常见的做法，特别是在进行模型推理（即测试或部署阶段）时，我们通常不需要计算梯度，因此可以分离张量以节省资源和提高效率。
