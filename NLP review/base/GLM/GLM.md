# GLM（Generative Language Model） 模型


---

自然语言处理NLP 技术中通常包含**三类任务**：自然语言理解NLU（包括文本分类、分词、句法分析、信息抽取等）、有条件生成任务（seq-seq，如翻译任务、QA）和无条件生成任务（用预训练模型直接生成内容）。

当前**预训练模型**也主要包括三类：自编码模型、自回归模型和编码解码模型。但这些预训练模型都不足以在所有 NLP 任务中都能展现出良好的性能。清华大学针对上述三种任务提出了一种基于**自回归空白填充**的通用语言模型（GLM），在兼顾三方面任务，且性能表现良好。在持续的探索中，GLM系列模型发布了GLM-130B、ChatGLM、ChatGLM-6B、ChatGLM2-6B等大模型组。

