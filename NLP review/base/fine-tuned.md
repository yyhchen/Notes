# fine-tuned 涉及到的一些概念

---


### adaptation 和 fine-tuned 区别与联系?
在自然语言处理（NLP）中，"adaptation"和"fine-tuning"都是指对预训练模型进行调整以适应特定任务或领域的过程。这两个术语有时可以互换使用，但它们在概念上有所不同，并且在实际应用中有不同的重点。

**Fine-tuning（微调）：**
Fine-tuning通常指的是在预训练模型的基础上，通过在特定任务上继续训练（即使用任务特定的数据对模型进行进一步训练）来调整模型的参数。这个过程旨在让模型学习任务特定的特征，从而提高在特定任务上的性能。Fine-tuning通常涉及更新模型的全部或大部分参数，以适应新的数据分布。

**Adaptation（适应）：**
Adaptation是一个更广泛的概念，它包括了fine-tuning在内的各种方法，用于调整预训练模型以适应新的设置或环境。除了fine-tuning之外，adaptation还可以包括其他技术，如特征提取（使用预训练模型的输出作为特征，然后在这些特征上训练一个新的分类器）、参数共享、模型压缩、知识蒸馏、使用特定领域的嵌入等。==**Adaptation的目的不一定是更新模型的参数**==，而是让模型更好地适应新的条件。

<br>

**区别：**
- Fine-tuning侧重于通过继续训练来调整预训练模型的参数，而adaptation是一个更广泛的概念，包括了fine-tuning以及其他适应模型的方法。
- Fine-tuning通常涉及较大的模型参数更新，而adaptation可能包括参数更新或使用预训练模型的其他方式。

**联系：**
- **Fine-tuning是adaptation的一种形式**，即通过调整模型参数来适应新的任务或领域。
- 两者都旨在提高预训练模型在特定任务或领域上的性能。

在实际应用中，fine-tuning是最常见的adaptation方法之一，特别是当有足够的任务特定数据可用时。然而，在数据稀缺或计算资源受限的情况下，可能会考虑其他adaptation技术，如参数效率高的方法，如adapter layers、prefix tuning等，它们只调整模型的一小部分参数。


<br>
<br>
<br>


### 什么是 adapter tuning？
Adapter Tuning是一种用于自然语言处理（NLP）任务的模型适应技术，它允许在保持预训练模型大部分参数不变的情况下，**通过添加少量的可训练参数来适应特定任务**。这种技术是由德国乌尔姆大学和伦敦大学学院的研究者在2019年提出的。

在Adapter Tuning中，不是对整个预训练模型进行微调，**而是在模型的每个层中==插入==一个小的、可训练的模块，这些模块通常包含较少的参数**。**这些模块称为“adapter”**，它们对输入数据进行轻量级的变换，从而使得模型能够适应新的任务或领域。

**Adapter Tuning的主要优点包括：**
1. **参数效率**：由于**只训练少量的adapter参数**，而不是整个模型的参数，Adapter Tuning能够显著减少适应新任务所需的计算资源和时间。
2. **知识保留**：Adapter Tuning保留了预训练模型的大部分参数，这意味着模型可以保持预训练阶段学到的通用知识。
3. **快速适应**：Adapter的结构使得模型能够快速适应新的任务或领域，而无需对整个模型进行全面的再训练。
4. **多任务学习**：Adapter Tuning可以用于多任务学习场景，其中单个模型需要适应多个任务。**通过为每个任务训练不同的adapter**，可以避免任务间的干扰。


Adapter Tuning与LoRA、Prefix Tuning等其他微调技术类似，都是为了在保持预训练模型不变的同时，通过添加少量可训练参数来适应新任务。这些技术的出现，使得在资源有限的情况下对大规模预训练模型进行定制化调整成为可能。
