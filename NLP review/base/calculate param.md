
---

>[!NOTE]
>以 fp16 全参微调 Llama 7B为例子, 计算显存占用量

考虑三个主要部分：**模型参数**、**优化器状态**和**激活值**。以下是详细的计算过程：


### **1. 模型参数（14GB）**
- **参数数量**：LLaMA 7B共有 **7,000,000,000（7B）** 个参数。
- **存储精度**：通常使用 **float16（16位，2字节）** 来存储参数以节省内存。
- **计算公式**：

  $$\text{参数内存} = 7B \times 2 \text{字节} = 14,000,000,000 \text{字节} = 14 \text{GB}$$
  



### **2. Adam优化器状态（42GB）**
Adam优化器需要存储以下状态：
- **梯度（Gradient）**：每个参数的梯度。
- **一阶矩（m）**：Adam的动量项。
- **二阶矩（v）**：Adam的方差项。

- **存储精度**：假设梯度、m、v均使用 **float16（2字节）**。
- **每个参数的存储**：每个参数需要存储 **3个状态**（梯度、m、v），每个状态占2字节：
  
$$  \text{每个参数的优化器状态内存} = 3 \times 2 \text{字节} = 6 \text{字节}$$
  
- **总内存**：
  $$\text{优化器状态内存} = 7B \times 6 \text{字节} = 42,000,000,000 \text{字节} = 42 \text{GB}$$
  


### **3. 激活值（2GB）**
激活值指前向传播过程中存储的中间结果，用于反向传播计算梯度。其大小取决于：
- **模型结构**：LLaMA的Transformer层包含自注意力和前馈网络。
- **序列长度**：假设最小批量（batch size=1）和典型序列长度（如512）。
- **存储精度**：通常使用 **float32（4字节）** 来存储激活值以避免数值精度问题。

#### **详细计算步骤**：
1. **假设的模型参数**：
   - **隐藏层大小（H）**：假设为 **4096**（LLaMA 7B的典型值）。
   - **前馈层中间维度**：通常为 **4H = 16384**。
   - **层数（L）**：假设为 **32层**。

2. **每层激活存储**：
   - **自注意力部分**：
     - Q、K、V矩阵各存储为 **batch_size × seq_len × H**：
       $$3 \times (1 \times 512 \times 4096) \times 4 \text{字节} = 3 \times 8,388,608 \times 4 = 24 \text{MB}$$
    
   - **前馈网络部分**：
     - 中间激活存储为 **batch_size × seq_len × 4H**：
       $$(1 \times 512 \times 16384) \times 4 \text{字节} = 33,554,432 \times 4 = 32 \text{MB}$$
    
   - **每层总激活存储**：

     $$24 \text{MB} + 32 \text{MB} = 56 \text{MB}$$

3. **总激活存储**：
   - **32层的总激活内存**：
     $$32 \times 56 \text{MB} = 1,792 \text{MB} \approx 1.8 \text{GB}$$
   - **四舍五入后**：约 **2GB**。



### **总内存需求**
$$\text{总内存} = \text{参数} + \text{优化器状态} + \text{激活值} = 14 \text{GB} + 42 \text{GB} + 2 \text{GB} = 58 \text{GB}$$




>[!TIP]
>使用**梯度检查点（Gradient Checkpointing）**：若使用该技术，激活存储可大幅减少。

