# Seq2Seq model

[Sequence to Sequence Learning with Neural Networks](https://arxiv.org/abs/1409.3215)

[Seq2Seq模型详解](https://www.jianshu.com/p/80436483b13b)

---

Seq2Seq（Sequence to Sequence）模型是一种用于处理序列到序列映射问题的框架，常用于机器翻译、对话系统、文本摘要等自然语言处理任务。该模型由两个主要的递归神经网络（RNN）组成：一个用于编码（Encoder）的输入序列，另一个用于解码（Decoder）输出序列。
### 编码器（Encoder）
编码器的作用是将可变长度的输入序列编码成一个固定长度的向量。这个向量通常被认为是输入序列的语义表示，包含了输入序列的必要信息。编码器通常是一个RNN模型，可以是简单的RNN、LSTM（Long Short-Term Memory）或GRU（Gated Recurrent Unit）。
在处理输入序列时，编码器逐个读取输入序列中的元素（如单词或字符），并在每个时间步更新其隐藏状态。**最后一个时间步的隐藏状态被用作整个序列的编码表示**。
### 解码器（Decoder）
解码器的作用是根据编码器提供的序列编码向量生成输出序列。解码器也是一个RNN模型，它使用编码器的最终隐藏状态作为其初始隐藏状态，并生成一个序列，这个序列的每个元素都是基于之前生成的元素和当前的隐藏状态计算得出的。
在解码器的每个时间步，它的输出可以是一个词汇表中的单词的概率分布，然后通过采样或贪心选择最可能的单词作为该时间步的输出。这个输出又可以作为下一个时间步的输入。
### 注意力机制（Attention Mechanism）
**基本的Seq2Seq模型存在一个问题**，即它必须将整个输入序列的信息压缩到一个固定长度的向量中，这在长序列上可能会导致信息丢失。为了解决这个问题，注意力机制被引入到Seq2Seq模型中。
注意力机制允许解码器在生成每个输出时关注输入序列的不同部分。它通过计算一个权重向量，这些权重表示输入序列中每个元素对当前输出元素的重要程度。然后，这些权重用于对输入序列的隐藏状态进行加权平均，得到一个上下文向量，该向量与解码器的输入和隐藏状态一起用于生成输出。
### 训练
Seq2Seq模型的训练通常使用最大似然估计，即优化模型以最大化给定输入序列时目标输出序列的概率。这通常通过反向传播算法和梯度下降优化来完成。
### 应用
Seq2Seq模型在许多NLP任务中都取得了成功，包括：
- 机器翻译：将一种语言的序列转换为另一种语言。
- 对话系统：根据用户的输入生成回应。
- 文本摘要：将长文本压缩为简洁的摘要。
- 代码生成：将自然语言描述转换为编程代码。
Seq2Seq模型是NLP中序列处理任务的一个重要里程碑，尽管近年来基于注意力机制的Transformer模型已经取代了传统的RNN在许多任务中的地位，但Seq2Seq模型仍然是理解现代序列处理模型的重要基础。




<br>
<br>



### seq2seq中的 teacher forcing

在Seq2Seq模型中，"teacher forcing"是一种**训练策略**，用于在训练过程中提供更稳定的梯度，并加速模型的收敛。Teacher forcing是指在**解码器训练过程中**，不是始终使用上一步的输出作为下一步的输入，而是有时直接使用目标序列的真实值作为输入。
具体来说，在标准的Seq2Seq模型中，解码器在时间步 \( t \) 的输入通常是时间步\( t-1 \)的输出（如果输出是词汇表中的单词，则是该单词的嵌入）。然而，在teacher forcing中，解码器在训练过程中，有一定概率（这个概率可以是一个固定的值，也可以是随时间变化的）直接接收目标序列中的下一个真实单词作为输入，而不是使用自己上一时间步的输出。
这样做的好处是：
1. **减少了错误累积**：因为在序列生成过程中，一旦模型在某个时间步生成了错误的输出，这个错误很可能会在后续的时间步中累积，导致模型偏离正确的输出路径。Teacher forcing通过提供正确的输入，减少了这种错误累积的可能性。
2. **提高了训练稳定性**：使用真实目标值作为输入可以提供更稳定的梯度，有助于网络的训练。
3. **加速收敛**：由于模型在训练过程中总是接收到正确的输入，这有助于模型更快地学习到正确的映射关系。
然而，teacher forcing也有其缺点，它可能导致模型在训练时过度依赖于这些正确的输入，而在测试时表现不佳，因为测试时模型必须使用自己的输出来生成下一个输入。这种现象被称为"exposure bias"。
为了缓解这个问题，研究人员通常会结合使用teacher forcing和没有teacher forcing的方法，即有时使用模型自己的输出来作为下一步的输入。此外，还有一些技术如Scheduled Sampling，它动态地调整使用teacher forcing的概率，随着训练的进行逐渐减少使用真实目标值的频率，使模型能够逐渐适应使用自己的输出来进行生成。
