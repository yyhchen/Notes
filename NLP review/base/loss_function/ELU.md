## ELU函数（Exponential Linear Unit）

---

<br>

### ELU函数的定义

ELU函数是一种近年来提出的激活函数，旨在解决ReLU函数在负区间输出为0的问题，从而更好地拟合数据。其数学表达式为：

$$\mathrm{ELU}(x)=\begin{cases}x,&\mathrm{~if~}x>0\\\alpha*(\exp(x)-1),&\mathrm{~if~}x\leq0&\end{cases}$$

其中，α是一个可调超参数，通常为一个小的正数。


如下图所示：
![ELU](/NLP%20review/assets/elu.png)


<br>

### ELU函数的特性

* **负区间非线性**：与ReLU不同，ELU在负区间引入了指数函数，使得函数在负区间具有非线性。
* **输出的均值接近于零**：ELU函数的输出的均值接近于零，这有助于加快模型的收敛速度。
* **平滑过渡**：ELU函数在0点处是连续可导的，这使得优化器更容易收敛。

<br>

### ELU函数的优点

* **缓解梯度消失**：ELU函数在负区间具有非零梯度，这有助于缓解深度神经网络中的梯度消失问题。
* **提高网络的精度**：ELU函数的非线性特性有助于提高网络的表达能力，从而提高模型的精度。
* **加速收敛**：ELU函数输出的均值接近于零，这有助于加快模型的收敛速度。

<br>

### ELU函数的缺点

* **计算复杂度略高于ReLU**：由于引入了指数运算，ELU函数的计算复杂度略高于ReLU。

<br>

### ELU函数与ReLU函数的比较

| 特性        | ReLU                                    | ELU                                      |
| ----------- | -------------------------------------- | ---------------------------------------- |
| 负区间输出 | 0                                       | α * (exp(x) - 1)                         |
| 连续性      | 不连续                                    | 连续                                      |
| 可导性      | 在x=0处不可导                            | 在x=0处可导                              |
| 均值        | 大于0                                     | 接近于0                                    |
| 梯度消失问题 | 容易出现梯度消失                        | 缓解梯度消失                            |


<br>

### 结论
ELU函数是一种性能优越的激活函数，它在一定程度上克服了ReLU函数的缺点。在实际应用中，ELU函数可以作为ReLU函数的一种替代，尤其是在需要更快的收敛速度和更好的性能时。

