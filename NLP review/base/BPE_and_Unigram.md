# BPE and Unigram

---

BPE（Byte Pair Encoding）和 Unigram 两种子词分词算法的原理和区别。

<br>

### BPE（Byte Pair Encoding）

BPE 是一种基于频率的分词算法，它通过迭代地合并最频繁的字符对来生成子词单元。BPE 的核心思想是从最小的单元（单个字符）开始，通过多次合并频率最高的字符对，逐渐生成常见的子词单元。

**步骤**：
1. 初始化：将所有文本拆分成单个字符。
2. 统计：计算所有字符对的频率。
3. 合并：找到频率最高的字符对，将其合并为一个新的子词单元。
4. 重复步骤 2 和 3，直到达到预定的词汇表大小。

**示例**：
假设输入文本为 "banana nana".

初始状态：
```
b a n a n a  _  n a n a
```
合并最频繁的字符对（假设 "na" 最频繁）：
```
b a na na  _  na na
```
再次合并最频繁的字符对（假设 "na" 再次最频繁）：
```
b a nana  _  nana
```
继续合并，直到达到预定的词汇表大小。

最终词汇表可能是：
```
{"b", "a", "n", "na", "nana"}
```


<br>
<br>
<br>


### Unigram

Unigram 分词是一种概率模型，它通过最小化编码成本来选择最优的子词单元。该模型会先生成一个初始的子词单元集合，然后通过迭代优化去掉不常用的子词，保留最有用的子词单元。

**步骤**：
1. 初始化：生成初始的子词单元集合，通常使用一些启发式方法（如 BPE 或直接将常见词语作为初始子词）。
2. 计算：根据当前的子词集合，对所有文本进行分词，计算每个子词的概率。
3. 最小化损失：根据子词概率和损失函数，删除最不常用的子词。
4. 重复步骤 2 和 3，直到达到预定的词汇表大小或损失函数收敛。

**示例**：
假设初始子词集合为 {"b", "a", "n", "na", "nana"}.

初始分词：
```
banana nana -> b a na na  _  na na
```
**计算每个子词的概率和损失函数。**

**删除不常用的子词**（假设 "b" 和 "a" 频率低）：
```
保留 {"n", "na", "nana"}
```
重新分词并计算损失函数，继续迭代，直到得到最优子词集合。

<br>
<br>
<br>

### BPE 和 Unigram 的区别

1. **算法基础**：
   - **BPE**：基于频率合并字符对，迭代生成子词单元。
   - **Unigram**：基于概率模型，优化子词集合以最小化编码成本。

2. **生成方式**：
   - **BPE**：从字符开始，通过合并最频繁的字符对逐步生成子词。
   - **Unigram**：从初始子词集合开始，通过删除不常用子词优化子词集合。

3. **子词集合的确定**：
   - **BPE**：通过合并操作逐步确定子词集合。
   - **Unigram**：通过最小化损失函数确定最优子词集合。

4. **适用场景**：
   - **BPE**：适用于需要高效分词和处理较大文本的场景，如语言模型训练。
   - **Unigram**：适用于需要高准确度分词和细粒度子词控制的场景，如机器翻译和文本生成。

<br>

### 具体例子

假设文本为 "hello hello world".

#### BPE
初始状态：
```
h e l l o  _  h e l l o  _  w o r l d
```
第一步合并 "l l"：
```
h e ll o  _  h e ll o  _  w o r l d
```
第二步合并 "e ll"：
```
h ell o  _  h ell o  _  w o r l d
```
第三步合并 "h ell"：
```
hell o  _  hell o  _  w o r l d
```
依次类推，直到达到词汇表大小。

#### Unigram
初始子词集合 {"h", "e", "l", "o", "w", "r", "d", "he", "llo", "wo", "rl", "ld"}.

计算概率，删除不常用子词，如 "h" 和 "e".

重新分词，继续优化子词集合，最终可能得到 {"hell", "o", "wo", "rld"}.
