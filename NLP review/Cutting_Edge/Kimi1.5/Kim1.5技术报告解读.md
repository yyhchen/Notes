
---

>[!tip] 原论文
>[Kimi k1.5: Scaling Reinforcement Learning with LLMs](https://arxiv.org/abs/2501.12599)


Kimi的预训练阶段包含==**三个阶段**==，结合多模态数据（文本、视觉、OCR等）进行分阶段训练:

1. **视觉-语言预训练阶段**  
   建立语言基础能力并逐步融合多模态数据，通过文本与视觉信息的联合训练提升跨模态理解能力

2. **冷启动阶段（冷却阶段）**  
   通过模型融合（Model Fusion）等技术优化模型性能，可能涉及对初始预训练模型的参数调整或架构改进

3. **长文本激活阶段**  
   在预训练后期引入长文本数据集（如扩展至128K上下文长度），增强模型对长文本的理解和生成能力。此阶段通过严格的数据质量控制，确保训练数据的相关性、多样性及平衡性


>[!NOTE] 冷却阶段(退火阶段)
>1. **能力巩固**
>	- 在初始的Vision-language预训练后，模型已具备基础的多模态理解能力。Cooldown阶段通过**精选数据（curated data）​**和**合成数据（synthetic data）​**，进一步强化模型在需要逻辑推理（如数学、代码）和知识处理（如事实性问答）任务上的表现。
>	- 例如，可能针对数学问题生成更多变体，或通过知识图谱增强事实性问答的训练数据。
>---
>
>2. **数据优化**
>	- **精选数据**：选择高质量、高难度的样本（如竞赛题目、专业领域问题），提升模型处理复杂问题的能力。
>	- **合成数据** ：利用规则或生成模型（如自动生成代码测试用例、数学证明步骤）创建针对性数据，填补真实数据中的不足，增强泛化性。
>---
>
>3. **过渡到长上下文训练**：
>	- 在进入**Long-context activation**​（支持128k tokens的上下文）前，cooldown阶段确保模型在**短上下文任务中足够鲁棒**。例如:
>		- 解决数学题时，模型需精准定位关键步骤，避免长上下文中的干扰。
>		- 处理知识问答时，快速检索相关信息，减少冗余推理
>---
>4. **训练策略调整**
>	- 可能降低学习率或调整优化器参数，避免预训练后的性能震荡
>	- 采用课程学习（Curriculum Learning），从简单任务逐步过渡到复杂任务，平衡模型的学习曲线

**对比其他阶段**：

- ​**预训练（Vision-language）​**：广泛学习语言和多模态关联（如图文匹配）。
- ​**Cooldown**：针对性强化推理和知识任务，类似“专项特训”。
- ​**Long-context activation**：扩展上下文容量，适配长文本/多模态输入（如整本书分析、复杂流程图解析）。
> 并且 long-context activation 这一步是渐进拓展的，4k -> 32k -> 128k (原文提到)



>[!warning] 需要注意的是！
>Cooldown 阶段可不是 SFT哦！(**而是针对性预训练**)
>
>在论文的附录B中有介绍到，这里的阶段还是 pre-train，因为训练目标任务仍然是 NTP (next token prediction)

| **维度**    | ​**Cooldown阶段**               | ​**监督微调（SFT）​**             |
| --------- | ----------------------------- | --------------------------- |
| ​**主要目标** | ​**巩固多模态能力**​（推理、知识、跨模态对齐）    | ​**适应特定任务**​（如对话、分类、生成）     |
| ​**数据性质** | 混合使用**精选数据（高难度任务）​**与**合成数据** | 主要依赖**人工标注的高质量任务数据**​（如问答对） |
| ​**训练范围** | 覆盖**多任务、多领域**​（如数学、代码、事实问答）   | 聚焦**单一任务或垂直领域**​（如客服对话）     |
| ​**优化策略** | 可能调整学习率、优化器，但**不显著改变模型架构**    | 可能修改损失函数或添加任务头（如分类器）        |



- **Cooldown**更接近**通用能力的预训练延伸**，而**SFT**是**任务导向的最终适配**。

- 如果cooldown阶段大量使用人工标注的监督数据，则可视为**广义的SFT**；但若以合成/弱监督数据为主，则与SFT有本质区别。

- ==实际论文中需结合具体实现判断==，但核心差异在于**是否以任务性能为直接优化目标**。

---
