# LLM涉及到的catastrophic forgetting（灾难性遗忘问题）


---


###1. **遗忘的原因**
   
* **固定的神经网络**
结构一旦确定，训练过程中很难调整。神经网络的结构直接决定学习模型的容量。==固定结构的神经网络意味着模型的容量也是有限的==，在容量有限的情况下，神经网络为了学习一个新的任务，就==必须擦除旧有的知识==。
$\quad$


* **对抗性差，对扰动敏感**
深度学习的隐含层的神经元是全局的，==单个神经元的细小变化能够同时影响整个网络的输出结果==。另外，所有前馈网络的参数与输入的每个维度都相连，新数据很大可能改变网络中所有的参数。我们知道，==对于本身结构就已经固定的神经网络，参数是关于知识的唯一变化量==。如果变化的参数中包含与历史知识相关性很大的参数，那么最终的效果就是，新知识覆盖了旧的知识
（这里提到的`相关性很大`指的就是==新参数包含了与以前学到的知识或模式**相似**的信息==）
