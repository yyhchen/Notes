# LLM涉及到的catastrophic forgetting（灾难性遗忘问题）


---


### 1. **遗忘的原因**
   
* **固定的神经网络**
结构一旦确定，训练过程中很难调整。神经网络的结构直接决定学习模型的容量。==固定结构的神经网络意味着模型的容量也是有限的==，在容量有限的情况下，神经网络为了学习一个新的任务，就==必须擦除旧有的知识==。
$\quad$


* **对抗性差，对扰动敏感**
深度学习的隐含层的神经元是全局的，==单个神经元的细小变化能够同时影响整个网络的输出结果==。另外，所有前馈网络的参数与输入的每个维度都相连，新数据很大可能改变网络中所有的参数。我们知道，==对于本身结构就已经固定的神经网络，参数是关于知识的唯一变化量==。如果变化的参数中包含与历史知识相关性很大的参数，那么最终的效果就是，新知识覆盖了旧的知识
（这里提到的`相关性很大`指的就是==新参数包含了与以前学到的知识或模式**相似**的信息==）



<br>



### 缓解灾难性遗忘的一些措施方法

大型预训练模型在微调过程中面临的“灾难性遗忘”（catastrophic forgetting）问题是指模型在适应新任务或新数据时，可能会忘记之前学到的知识或技能。为了避免这个问题，可以采取以下几种策略：
1. **渐进式微调（Progressive Fine-tuning）**：
   不是一次性将模型暴露在新任务上，而是逐渐增加新任务的样本比例，同时维持一定比例的原始任务样本。这样可以使得模型逐渐适应新任务，同时保留旧知识。
2. **弹性权重共享（Elastic Weight Consolidation, EWC）**：
   EWC通过为每个参数分配一个重要性权重来防止模型在微调时过度改变重要参数。这些权重是根据参数在原始任务上的重要性计算得出的，并在微调过程中使用正则化项来限制这些参数的变化。
3. **回放（Replay）**：
   在微调过程中，定期将模型暴露于原始任务的样本上，这可以是通过回放存储的样本或使用一个小型的原始任务数据集。这种方法类似于人类学习中的复习，有助于模型保持旧知识。
4. **正则化（Regularization）**：
   在微调过程中，使用正则化技术，如L2正则化或Dropout，可以防止模型过拟合新任务，从而有助于保持旧知识。
5. **固定某些层（Layer Freezing）**：
   在微调时，可以选择性地固定模型的一部分层，特别是那些捕获通用语言特征的层。这样，只有顶层或部分层会适应新任务，而其他层保持不变。
6. **使用低秩适配（Low-Rank Adaptation）**：
   如LoRA方法所示，通过添加低秩矩阵来捕捉新任务的信息，而不是直接更新原始权重矩阵。这种方法可以减少需要更新的参数数量，从而减少对原始知识的干扰。
7. **持续学习（Continual Learning）**：
   持续学习是一种学习范式，其中模型顺序学习多个任务，同时尝试保留之前学到的知识。这可以通过上述方法的组合来实现。
8. **任务特定的适配器（Task-Specific Adapters）**：
   在模型中插入小的任务特定模块（适配器），这些适配器负责将模型的通用表示转换为特定于任务的表示。这样可以使得模型的主体保持不变，而适配器学会如何适应新任务。
这些策略可以单独使用，也可以组合使用，以有效地减少大型预训练模型在微调过程中的灾难性遗忘问题。选择哪种策略取决于具体的应用场景、资源限制和任务要求。

