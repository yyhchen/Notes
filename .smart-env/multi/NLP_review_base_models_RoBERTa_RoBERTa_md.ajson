
"smart_sources:NLP review/base/models/RoBERTa/RoBERTa.md": {"path":"NLP review/base/models/RoBERTa/RoBERTa.md","last_embed":{"hash":null},"embeddings":{},"last_read":{"hash":"95bfd4e3d956499abab6928c77c7a9a89eb9cae353ae5989fe4c48ef9814dd74","at":1746436084101},"class_name":"SmartSource","last_import":{"mtime":1714053496808,"size":2554,"at":1746436084101,"hash":"95bfd4e3d956499abab6928c77c7a9a89eb9cae353ae5989fe4c48ef9814dd74"},"blocks":{"#RoBERTa":[1,79],"#RoBERTa#{1}":[2,79],"#---frontmatter---":[6,null]},"outlinks":[{"title":"RoBERTa: A Robustly Optimized BERT Pretraining Approach","target":"https://arxiv.org/pdf/1907.11692.pdf","line":2},{"title":"pytorch/fairseq","target":"https://github.com/facebookresearch/fairseq","line":4},{"title":"alt text","target":"image.png","line":45},{"title":"alt text","target":"image-1.png","line":66},{"title":"浅谈Byte-Level BPE","target":"https://zhuanlan.zhihu.com/p/146114164","line":77}]},
"smart_sources:NLP review/base/models/RoBERTa/RoBERTa.md": {"path":"NLP review/base/models/RoBERTa/RoBERTa.md","embeddings":{"TaylorAI/bge-micro-v2":{"vec":[-0.13195413,-0.03372232,-0.06721058,0.00904281,-0.03312578,-0.01771619,-0.00904201,-0.00503321,0.05415482,0.04784826,0.02749128,-0.09039625,0.04732366,0.08937117,0.04282869,0.01104167,0.05960178,0.02505682,-0.06520891,-0.03159532,0.0197107,-0.03629227,0.03378476,-0.05938462,0.02701068,-0.02142481,-0.00710057,-0.04938276,0.02661004,-0.23061897,-0.02720935,0.0412248,0.07316774,0.01508312,-0.00561501,0.08516707,-0.05151515,0.0376157,0.00173458,-0.03657362,0.02932065,0.03386034,-0.03047192,-0.02610905,0.04235092,-0.08199365,0.04037434,-0.02063051,-0.07437216,-0.04928645,-0.01582381,-0.03156137,0.00521698,0.00168295,0.02768041,0.00420676,0.05336959,-0.02122233,0.03819539,0.06462079,-0.00975347,0.05568406,-0.22945309,0.11371444,-0.01302972,-0.01340515,-0.06339863,-0.01130385,-0.00236883,0.03534799,-0.05193689,0.03400537,-0.00461487,0.0524967,0.00253273,0.02545059,0.0317595,0.02038194,0.00241779,0.015299,0.01649683,0.01737932,-0.04973787,-0.03451923,0.00987783,-0.00187442,0.01020546,-0.0808634,0.01977898,-0.0443671,0.0114279,-0.0349134,0.03234805,-0.00109915,0.04228739,0.013528,0.05067766,0.03251884,-0.0311631,0.10456316,-0.05005794,0.01175362,-0.05333898,-0.00601857,-0.02207698,-0.0032443,-0.00031072,-0.01202587,0.02136565,-0.02232158,0.00000959,-0.02382506,-0.00309028,-0.0266166,0.01656717,0.02343159,0.09001476,-0.01043555,0.02277978,0.01207738,0.03032281,0.01090447,0.07192747,-0.03101625,-0.01710522,-0.03536669,0.02998003,0.08526877,0.02544386,0.03016437,0.06564097,0.02027924,-0.04970063,-0.01058021,0.00709169,-0.04087324,-0.02180894,-0.00834758,0.00041837,-0.03012799,-0.07212004,-0.04778992,0.00952544,-0.05531312,-0.05135314,0.16953619,-0.0470949,0.00287897,-0.02992078,-0.1058,0.06910535,0.02063239,0.02016114,-0.00208087,0.05230927,0.0114391,0.03767293,0.10423538,-0.06850108,-0.02554847,-0.00637688,-0.06809971,-0.01429112,0.02988323,0.01260144,-0.09165397,-0.02662963,-0.03173856,-0.00072806,-0.08322489,0.05663095,-0.00512869,-0.04260527,0.08137744,0.00380492,-0.05110961,-0.03756672,0.00827351,0.0235436,0.00188595,-0.03282842,-0.0406558,0.00880763,0.03204599,0.0006232,-0.02189999,0.02461248,0.01455737,0.03753482,0.01198914,-0.05180458,0.02788541,-0.01872817,0.06971096,0.00758549,-0.03255129,0.02168767,-0.01609402,0.0315857,-0.02474477,0.07002641,0.02242978,0.01951068,0.00584392,-0.00482886,0.00255821,0.03080978,-0.06144731,0.04409057,0.02660522,-0.06120973,-0.03915793,0.01412406,-0.05345589,-0.08141521,0.0140184,-0.01665995,0.0565953,0.01186191,0.05102036,0.02800401,0.04490805,-0.08048836,-0.21359046,0.0257609,-0.0002837,-0.03713754,0.08893938,-0.07318472,0.03703928,-0.00449577,0.08280727,0.13550092,0.01693989,-0.02269585,-0.00938793,0.06132744,-0.0298461,0.03838182,0.00720364,0.03470822,-0.01638911,-0.00416586,-0.0533846,0.04961057,-0.02274742,-0.03918496,0.02943632,0.01001882,0.10324533,0.00319786,0.02333868,-0.01769631,0.013802,0.04679147,-0.0277277,-0.10784172,0.02177189,0.0286115,-0.01708755,0.01681739,0.02087487,-0.0356798,-0.02385566,0.00916387,0.00414773,-0.10873105,-0.07979272,-0.04472214,-0.01135494,0.00803968,-0.04502924,0.04217565,0.02920036,0.02928802,0.02421428,0.05176271,0.0535339,-0.06986452,-0.08280633,-0.01889709,-0.01852156,0.04745844,0.0603884,-0.0806882,-0.00904973,-0.0648413,0.0293657,-0.02478699,-0.01757773,0.04153655,-0.02164476,0.01251082,-0.02371299,0.13556728,-0.00222099,0.01849166,0.07410476,-0.0354826,0.00659991,-0.01141667,-0.03262104,-0.00568049,0.07788769,-0.00674831,0.05503226,0.00696021,0.01778468,0.00414961,0.05426214,-0.00736977,0.04310767,0.03704095,-0.01880006,-0.05430209,-0.08747412,0.06021542,0.08313502,0.00614704,-0.28771058,0.00038297,-0.01790775,-0.00768409,-0.00072037,0.04107301,0.03057231,-0.05448379,0.02363826,0.01967283,-0.09485168,0.06740648,0.02128834,-0.00627756,-0.02274888,-0.00756541,0.04021288,-0.06043584,0.07771773,-0.04905242,-0.01241531,-0.00149707,0.1697875,-0.00016588,0.03250306,-0.00199825,-0.02317939,-0.04473257,0.02497496,-0.01108761,-0.03151715,0.01078532,0.09853859,-0.014927,0.04893766,0.03848686,-0.05435663,0.03944802,0.0201524,-0.0331969,-0.01766271,-0.00093671,0.01366566,-0.01638761,0.04226816,0.05298623,-0.02932695,-0.00788943,-0.00181522,0.04198758,0.02880614,0.04890906,0.0596346,-0.01725966,0.05549628,0.07502038,-0.02249044,-0.01502596,-0.03204112,-0.01633817,0.02674731,-0.02243636,-0.03480665,0.08794174,-0.01954337],"last_embed":{"hash":"95bfd4e3d956499abab6928c77c7a9a89eb9cae353ae5989fe4c48ef9814dd74","tokens":416}}},"last_read":{"hash":"95bfd4e3d956499abab6928c77c7a9a89eb9cae353ae5989fe4c48ef9814dd74","at":1746436110270},"class_name":"SmartSource","last_import":{"mtime":1714053496808,"size":2554,"at":1746436084101,"hash":"95bfd4e3d956499abab6928c77c7a9a89eb9cae353ae5989fe4c48ef9814dd74"},"blocks":{"#RoBERTa":[1,79],"#RoBERTa#{1}":[2,79],"#---frontmatter---":[6,null]},"outlinks":[{"title":"RoBERTa: A Robustly Optimized BERT Pretraining Approach","target":"https://arxiv.org/pdf/1907.11692.pdf","line":2},{"title":"pytorch/fairseq","target":"https://github.com/facebookresearch/fairseq","line":4},{"title":"alt text","target":"image.png","line":45},{"title":"alt text","target":"image-1.png","line":66},{"title":"浅谈Byte-Level BPE","target":"https://zhuanlan.zhihu.com/p/146114164","line":77}]},"smart_blocks:NLP review/base/models/RoBERTa/RoBERTa.md#RoBERTa": {"path":null,"embeddings":{"TaylorAI/bge-micro-v2":{"vec":[-0.13291268,-0.03178576,-0.06817137,0.00954119,-0.03260867,-0.01757564,-0.00759682,-0.00536376,0.05615384,0.04925792,0.02888438,-0.09115191,0.04685444,0.08905876,0.0438294,0.01155793,0.05809027,0.02484401,-0.06531896,-0.03160071,0.01746039,-0.03542261,0.03338005,-0.05866707,0.02567069,-0.02174893,-0.00901276,-0.04837476,0.02532911,-0.22946279,-0.02606829,0.04054317,0.07529911,0.01624932,-0.00703592,0.08406637,-0.05035999,0.03722409,0.00156868,-0.03635945,0.02992875,0.03381331,-0.03093252,-0.02354887,0.03975116,-0.0848799,0.03915287,-0.02015008,-0.07242578,-0.05098934,-0.01386236,-0.03273788,0.0038892,0.00181919,0.0247906,0.00385001,0.05371106,-0.0225576,0.03861187,0.06323207,-0.01061527,0.05383037,-0.22869983,0.1128547,-0.01289462,-0.01457069,-0.06127995,-0.01464354,-0.00468202,0.03344952,-0.05579083,0.03434928,-0.00514113,0.05128645,0.00161211,0.02460811,0.03090052,0.02092696,0.00054037,0.01639554,0.01472144,0.01622452,-0.04961891,-0.03507341,0.01248278,-0.00154096,0.01019103,-0.08045996,0.02047468,-0.04578699,0.0087023,-0.03422197,0.03224856,-0.00139428,0.04250873,0.01353938,0.05030812,0.03237593,-0.03061674,0.10542028,-0.05133446,0.0127954,-0.0529187,-0.00651042,-0.02249994,-0.00288174,-0.00084727,-0.00897874,0.01972392,-0.02280731,0.00106331,-0.02541911,-0.00169851,-0.02491731,0.01695553,0.02349919,0.08883546,-0.00632523,0.02559849,0.01200227,0.02886386,0.00921811,0.06967211,-0.0283316,-0.0158782,-0.03486755,0.02993965,0.08586578,0.0242131,0.02921354,0.06627244,0.02218842,-0.05075061,-0.00924805,0.00841905,-0.04117336,-0.02104709,-0.00739166,0.00113279,-0.03062624,-0.07395896,-0.04920778,0.00858914,-0.05575069,-0.05048199,0.16701601,-0.04808776,0.00482528,-0.02613151,-0.10390185,0.06907376,0.02145144,0.02119184,-0.00211873,0.05329156,0.01098492,0.03755185,0.104492,-0.06847139,-0.02387326,-0.00779405,-0.06952816,-0.012661,0.02785005,0.01221811,-0.09349689,-0.02691307,-0.03295014,-0.001726,-0.08506966,0.05802869,-0.00600335,-0.043485,0.08023523,0.00522785,-0.05120518,-0.03733024,0.01137909,0.02548851,-0.00156733,-0.03403808,-0.03954238,0.01117777,0.03319805,0.00090636,-0.02262793,0.02556809,0.01473058,0.03690187,0.01191359,-0.04724454,0.02913743,-0.02035479,0.06975518,0.00925631,-0.0326867,0.0245231,-0.01526081,0.03123074,-0.02546049,0.07276828,0.02329893,0.01982398,0.00643776,-0.00360719,0.001026,0.03286315,-0.0623479,0.04425201,0.02511798,-0.06007281,-0.03761338,0.01474557,-0.05513828,-0.08351707,0.01482851,-0.0175565,0.0569544,0.01332265,0.05020471,0.02718232,0.04313854,-0.08105456,-0.21366866,0.02788332,0.00136628,-0.03849423,0.08894566,-0.07098724,0.03902928,-0.00383123,0.0836239,0.13325967,0.01797153,-0.02164379,-0.00842191,0.06317645,-0.03257813,0.04110441,0.00947025,0.03658779,-0.01477077,-0.00696942,-0.05402949,0.05037194,-0.02280123,-0.03664039,0.03247856,0.01113814,0.10227205,0.00375415,0.02218338,-0.01922091,0.01170603,0.04661238,-0.02891657,-0.10866212,0.01928457,0.03004489,-0.01651659,0.01742997,0.01869326,-0.03470182,-0.02285708,0.00783998,0.00571253,-0.10993361,-0.08001564,-0.04439021,-0.01155391,0.01022657,-0.04469704,0.04087544,0.02872018,0.02812422,0.02478041,0.0507167,0.05480912,-0.06991947,-0.08328643,-0.01847737,-0.0213718,0.0480322,0.06131195,-0.08338217,-0.01054397,-0.06598847,0.02884817,-0.02376443,-0.01975771,0.0410411,-0.02061378,0.0109726,-0.02310715,0.13540916,-0.00085843,0.01861171,0.07424902,-0.03823482,0.0092779,-0.01130072,-0.03248375,-0.00475486,0.07769209,-0.00441989,0.05231822,0.00919351,0.01948842,0.00412394,0.05383767,-0.00714539,0.04282742,0.03661152,-0.01856537,-0.05364167,-0.08524407,0.06057004,0.08427434,0.00612219,-0.28886685,0.00088537,-0.02038987,-0.0078297,-0.00369458,0.04051237,0.02913789,-0.05239049,0.02418453,0.01813551,-0.09444327,0.06750807,0.02199435,-0.0027189,-0.02211208,-0.0070163,0.03856858,-0.05860614,0.07622886,-0.051578,-0.01357193,-0.00177902,0.16787128,0.00111069,0.03060733,-0.00282659,-0.02366597,-0.04484201,0.02529485,-0.01107062,-0.03143292,0.01008991,0.09743892,-0.01429694,0.04995426,0.03820851,-0.05403591,0.03948666,0.02027655,-0.03664178,-0.01843082,-0.00153846,0.01275572,-0.01607377,0.04269249,0.05395436,-0.03146736,-0.0076312,-0.00273372,0.04233302,0.0290903,0.05009583,0.0607206,-0.01852208,0.0554799,0.07658783,-0.023562,-0.01175874,-0.03069359,-0.01570899,0.02832365,-0.02200954,-0.03527949,0.08741011,-0.01934738],"last_embed":{"hash":"95bfd4e3d956499abab6928c77c7a9a89eb9cae353ae5989fe4c48ef9814dd74","tokens":416}}},"text":null,"length":0,"last_read":{"hash":"95bfd4e3d956499abab6928c77c7a9a89eb9cae353ae5989fe4c48ef9814dd74","at":1746436110239},"key":"NLP review/base/models/RoBERTa/RoBERTa.md#RoBERTa","lines":[1,79],"size":1470,"outlinks":[{"title":"RoBERTa: A Robustly Optimized BERT Pretraining Approach","target":"https://arxiv.org/pdf/1907.11692.pdf","line":2},{"title":"pytorch/fairseq","target":"https://github.com/facebookresearch/fairseq","line":4},{"title":"alt text","target":"image.png","line":45},{"title":"alt text","target":"image-1.png","line":66},{"title":"浅谈Byte-Level BPE","target":"https://zhuanlan.zhihu.com/p/146114164","line":77}],"class_name":"SmartBlock"},
"smart_blocks:NLP review/base/models/RoBERTa/RoBERTa.md#RoBERTa#{1}": {"path":null,"embeddings":{"TaylorAI/bge-micro-v2":{"vec":[-0.13271427,-0.03116037,-0.06703635,0.00889819,-0.03163501,-0.01700261,-0.00921668,-0.00746369,0.05435988,0.0466534,0.02580111,-0.09146951,0.04641553,0.08946498,0.04085197,0.01095984,0.05926297,0.02526606,-0.06356712,-0.03150999,0.01980504,-0.0354986,0.03257182,-0.06050423,0.02818795,-0.02390077,-0.00779021,-0.04789593,0.0279541,-0.23059693,-0.02386534,0.03816442,0.07296494,0.01453271,-0.00623786,0.08314835,-0.04940065,0.03827006,0.00137336,-0.03632493,0.02969462,0.03547882,-0.0299336,-0.02640167,0.03808166,-0.08389936,0.03923832,-0.02238572,-0.07312392,-0.05318108,-0.01325392,-0.03326584,0.00561247,0.00144808,0.02602519,0.00411759,0.05173973,-0.0200009,0.03870396,0.06448336,-0.01154827,0.05413818,-0.22821613,0.11274114,-0.01406314,-0.01342449,-0.06358127,-0.01398961,-0.0043461,0.03435101,-0.05402872,0.03439909,-0.00317915,0.05114552,0.00282018,0.02388255,0.031055,0.01922169,-0.00008226,0.0156298,0.01502423,0.01649292,-0.0481415,-0.03593575,0.01168537,-0.00227837,0.01183338,-0.08234326,0.01783169,-0.04647091,0.01041532,-0.03578346,0.02910391,-0.00293191,0.04408561,0.01391243,0.05180878,0.03330899,-0.03181744,0.10481198,-0.05203783,0.01247417,-0.05213552,-0.00798395,-0.02101959,-0.00138566,-0.00149989,-0.00854138,0.02053754,-0.02310206,-0.00017693,-0.02477302,-0.0023584,-0.02477069,0.01525582,0.02424637,0.08703998,-0.00954399,0.02416405,0.01633846,0.02745392,0.01029548,0.06991667,-0.02907245,-0.01685426,-0.03352456,0.03069265,0.08701515,0.02258455,0.02992695,0.06519273,0.02026722,-0.05346483,-0.00872273,0.00976086,-0.04104909,-0.02266579,-0.00856384,0.00058293,-0.02940694,-0.07170522,-0.04588467,0.00910227,-0.05608422,-0.05230572,0.16640826,-0.04682973,0.00343262,-0.02704911,-0.10764174,0.06875579,0.01892325,0.0200199,-0.00264843,0.05330849,0.01190297,0.03693546,0.10473908,-0.06693444,-0.02365123,-0.00786389,-0.06634446,-0.01396486,0.02904104,0.01018155,-0.09169111,-0.02617343,-0.03347689,-0.00171089,-0.08236803,0.05548053,-0.00691525,-0.03977336,0.08098401,0.00387267,-0.05223321,-0.03954414,0.00960208,0.02492339,-0.00093173,-0.03314952,-0.03987333,0.01040344,0.03175352,0.00093848,-0.02248786,0.02440071,0.01590145,0.03927037,0.01390876,-0.04770816,0.0279239,-0.02036107,0.06603271,0.00768355,-0.0336385,0.02286605,-0.01646527,0.03304321,-0.02544643,0.07145091,0.02150774,0.01909893,0.00421643,-0.00148651,0.00072642,0.03198004,-0.06227051,0.04370908,0.02504197,-0.06050222,-0.03860632,0.01548245,-0.05252882,-0.08070044,0.01430573,-0.01634055,0.05964794,0.01353312,0.0509306,0.0283089,0.0433822,-0.08023781,-0.21351999,0.02552206,0.00128148,-0.03570426,0.08825629,-0.07214693,0.03854579,-0.00530931,0.08410808,0.13099678,0.01916971,-0.0208432,-0.00774198,0.06361167,-0.03198568,0.0418493,0.00975423,0.03607781,-0.0127156,-0.00455749,-0.05084071,0.05247612,-0.02406865,-0.03894299,0.03182121,0.0098169,0.10311473,-0.00082051,0.02330468,-0.01965422,0.01129345,0.04560588,-0.02932791,-0.10774845,0.02249992,0.03103496,-0.01419915,0.01522827,0.02077842,-0.03432147,-0.02410869,0.00848617,0.00529957,-0.11395758,-0.08176226,-0.04586569,-0.01153482,0.01000935,-0.04549237,0.04168002,0.03013774,0.02822997,0.02602421,0.04909347,0.05300042,-0.07038917,-0.08426426,-0.01765385,-0.02181234,0.04635768,0.06073469,-0.08523107,-0.01124007,-0.06471012,0.02846574,-0.02042252,-0.01661653,0.03927356,-0.01887047,0.01119157,-0.02448561,0.13390708,-0.00105825,0.02021312,0.07377645,-0.03419209,0.00722538,-0.00994763,-0.03429499,-0.00615674,0.0777633,-0.0034479,0.05230125,0.00871602,0.0197273,0.00327596,0.05653453,-0.00768433,0.0427566,0.03681072,-0.01766368,-0.05338115,-0.0851476,0.05867993,0.08483603,0.00676653,-0.29072765,-0.00132561,-0.02161209,-0.0087682,-0.00066751,0.04144241,0.03088514,-0.053189,0.02503087,0.01459286,-0.09806292,0.06689752,0.02142602,-0.0040576,-0.02256104,-0.00824303,0.03985815,-0.05890722,0.07618844,-0.05237713,-0.0118319,-0.00113835,0.17079152,0.00245955,0.03087301,-0.00184549,-0.01982642,-0.04534145,0.02646624,-0.01108957,-0.03045619,0.0105412,0.09998033,-0.01247306,0.04640773,0.04163211,-0.05417577,0.03814085,0.02083904,-0.03506607,-0.01822829,-0.00027636,0.01565146,-0.01635691,0.04291528,0.05624885,-0.02980854,-0.00682805,-0.00186988,0.04316159,0.02934646,0.05183988,0.05889244,-0.01784562,0.05630483,0.07652044,-0.02180822,-0.01335485,-0.03036911,-0.01629336,0.02890452,-0.02196159,-0.03407052,0.08845599,-0.01739804],"last_embed":{"hash":"681dd769d99d6463aef3e524f88fcf3c3b6112ccc74e4d3124c39c390e76ad78","tokens":416}}},"text":null,"length":0,"last_read":{"hash":"681dd769d99d6463aef3e524f88fcf3c3b6112ccc74e4d3124c39c390e76ad78","at":1746436110258},"key":"NLP review/base/models/RoBERTa/RoBERTa.md#RoBERTa#{1}","lines":[2,79],"size":1460,"outlinks":[{"title":"RoBERTa: A Robustly Optimized BERT Pretraining Approach","target":"https://arxiv.org/pdf/1907.11692.pdf","line":1},{"title":"pytorch/fairseq","target":"https://github.com/facebookresearch/fairseq","line":3},{"title":"alt text","target":"image.png","line":44},{"title":"alt text","target":"image-1.png","line":65},{"title":"浅谈Byte-Level BPE","target":"https://zhuanlan.zhihu.com/p/146114164","line":76}],"class_name":"SmartBlock"},
"smart_blocks:NLP review/base/models/RoBERTa/RoBERTa.md#---frontmatter---": {"path":null,"embeddings":{"TaylorAI/bge-micro-v2":{"vec":[-0.09686394,-0.02395676,0.0649756,0.00845303,0.03775631,-0.0472751,-0.05189418,0.02365751,0.04263203,0.04421689,0.05951185,0.00127931,0.01267474,0.02670363,0.02990627,0.03055503,-0.03254441,0.08024941,0.01564799,0.00359323,0.05570094,-0.02779596,0.00129716,-0.02920794,0.01828563,0.02884903,-0.05001942,-0.0004243,-0.02823704,-0.20618069,-0.03561611,0.02925762,0.0062679,0.04198279,0.05261869,0.05900024,-0.0424753,0.02035044,-0.01816942,0.01032357,0.02913704,-0.00464631,-0.01199724,-0.01236598,0.01022945,-0.02911206,0.00724368,-0.01796282,0.02408348,-0.05915301,0.03360983,-0.01905136,0.01723618,0.00449953,0.03603107,0.02594642,0.06002427,-0.02747946,-0.02036278,0.04837241,0.0270873,0.05369214,-0.18374634,0.00735575,0.05957274,0.01757345,0.02382321,-0.06903803,-0.01544916,0.03343613,-0.03060929,0.03963125,-0.01821169,0.07304693,-0.02561877,0.01455282,0.02737417,0.02471017,0.00753509,0.05725346,-0.07859214,-0.08817187,-0.03063454,0.00152193,-0.01757767,-0.04484691,-0.00781489,-0.0100529,0.04861667,0.01910747,-0.00099565,0.0088027,0.09635664,0.01348164,-0.03455305,0.01441428,-0.02927116,0.02575811,-0.05638466,0.1249724,-0.01980125,0.05350241,-0.04416466,-0.02361238,-0.00422808,-0.02496857,-0.02808594,0.01627202,0.05046541,-0.03202917,0.10909053,-0.03237688,0.07280211,-0.05334856,0.02599515,-0.0764724,0.08890983,0.05981461,-0.00651231,-0.05320559,-0.00907843,-0.05601641,0.07184371,-0.03550797,0.00396502,0.01243898,0.04719646,0.09366069,0.03906865,0.03617434,0.02306227,-0.00931678,-0.00523135,0.00507209,-0.01660597,-0.02557722,0.00726007,0.03485664,0.05145159,-0.04595749,-0.06343456,-0.07063692,-0.02658783,-0.02413233,-0.01719028,0.06858384,-0.04776996,0.04049857,0.00830381,0.03809578,0.00312259,0.06947184,-0.02257051,-0.01417172,0.01297784,-0.03731437,0.04411702,0.07022037,-0.06071238,-0.01773749,0.04124162,-0.07200699,-0.00662432,0.1070101,0.01192953,-0.04614701,0.01000655,-0.03403774,-0.00744098,-0.04714157,0.01607772,-0.01367552,-0.05609591,0.0121031,0.02616332,-0.02854711,-0.01399786,0.04815226,0.03632973,0.0147063,-0.03581991,-0.04358356,-0.01305171,0.00422707,0.01825741,-0.01912987,0.06937617,-0.04292946,0.01948249,0.00278595,-0.0937868,-0.01292752,-0.01086392,0.03868598,0.00221734,0.00135062,0.01271563,-0.01300802,-0.00802922,-0.0045228,0.06349556,0.04969944,0.00686291,-0.01804959,-0.0792684,0.05222892,-0.01018231,-0.0647799,0.01663105,0.06897723,-0.0207419,-0.0190397,0.0252649,-0.02999423,-0.07308231,-0.01591228,0.01595927,0.00431238,0.00391714,0.03040879,-0.04594371,0.07945976,-0.08497265,-0.2479707,0.05577215,0.00664487,-0.00668058,0.0185514,-0.0813334,-0.00439753,-0.04520662,0.02025669,0.1585657,-0.01150442,-0.03190473,-0.03382523,0.04520091,0.00392147,-0.00256263,0.04797512,-0.01989445,-0.11689316,-0.00241632,-0.01289996,-0.060771,-0.03228244,-0.08069301,0.03550985,-0.01802056,0.16015524,0.0773451,0.04313558,-0.03123327,0.01335939,0.0591848,-0.06168267,-0.17484133,0.00922716,-0.00108168,0.03591939,0.06439187,0.04836029,-0.03525601,-0.0060943,-0.00778059,-0.02091647,-0.08345607,0.00101507,-0.0288721,0.01928194,0.0055511,-0.02388146,0.05677704,0.02314419,0.02696846,0.03836093,0.07239016,0.00951322,-0.01770884,-0.06519391,-0.02874471,-0.03917343,0.10093483,0.00182377,0.03238943,0.02275826,-0.1237632,0.05366008,0.02237831,-0.07948919,0.06543898,0.0426942,-0.02964699,-0.03146441,0.05527228,-0.00440931,0.01765128,-0.03966307,-0.01355296,0.01265762,-0.02379734,-0.08446687,-0.044475,0.01881726,-0.01687117,0.02619473,-0.00846681,-0.02816189,0.03733926,-0.01537307,-0.05911668,0.07498583,0.03261773,-0.03113991,0.01469467,-0.05201452,0.06153491,0.14941591,-0.04207873,-0.2348582,0.00945759,0.03909518,-0.01164673,-0.04787099,0.06421287,0.00142133,-0.02899631,0.01392838,0.02009513,-0.05401231,0.06489453,0.01652634,-0.06576479,-0.02612119,0.01435816,0.01394308,0.00107812,0.10485312,-0.02437442,0.00877155,-0.02970978,0.15355332,0.00246792,0.0077453,-0.03666694,-0.04741674,-0.0306755,-0.02247047,-0.00511753,0.0224573,0.01108443,0.02647114,-0.0653614,0.04655415,0.01319613,-0.0590988,0.09248124,-0.00840306,-0.08884152,-0.0961508,-0.00324522,0.00717399,0.00349277,0.05654356,-0.04980656,-0.05875064,0.07579739,0.02148423,0.03066022,-0.04048044,-0.02100664,0.05867122,0.02368308,0.05502901,0.06406879,-0.01670963,0.0315049,-0.01610424,-0.02059422,0.02020103,0.03606841,0.01280155,0.01163895,-0.01255034],"last_embed":{"hash":null,"tokens":25}}},"text":null,"length":0,"last_read":{"hash":null,"at":0},"key":"NLP review/base/models/RoBERTa/RoBERTa.md#---frontmatter---","lines":[6,null],"size":0,"outlinks":[],"class_name":"SmartBlock"},
