# Multi-Modal Attention Network Learning for Semantic Source Code Retrieval
---
![alt text](image.png)

---

### Abstract
代码检索技术和工具在促进软件开发人员根据用户查询（例如，描述检索特定代码片段的功能的简短自然语言文本）从可用开源存储库中检索现有代码片段方面发挥着关键作用。尽管现有的努力在提高代码检索的有效性，但仍然存在两个主要问题阻碍它们在回答复杂查询时从大规模存储库中准确检索令人满意的代码片段。首先，现有的方法仅考虑源代码的浅层特征，例如方法名称和代码标记，而忽略了源代码的抽象语法树（AST）和控制流图（CFG）等结构化特征，其中包含丰富且良好的信息。源代码的定义语义。其次，虽然基于深度学习的方法在源代码的表示上表现良好，但缺乏可解释性，使得检索结果难以解释，并且几乎不可能理解源代码的哪些特征对最终结果贡献更大。

为了解决上述两个问题，本文提出了 `MMAN`，一种用于语义源代码检索的新型多模态注意力网络。开发了**一种全面的多模态表示来表示源代码的非结构化和结构化特征，其中一个 LSTM 用于表示代码的顺序标记，一个 Tree-LSTM 用于表示代码的 AST，一个 GGNN（门控图神经网络）用于表示 CFG代码**。此外，应用多模态注意融合层为源代码每种模态的不同部分分配权重，然后将它们集成到单个混合表示中。对大规模现实世界数据集的综合实验和分析表明，我们提出的模型可以准确地检索代码片段，并且优于最先进的方法。

<br>
<br>
<br>



### 1. Introduction
随着 GitHub [1] 和 StackOverflow [2] 等巨大源代码存储库的出现，搜索具有相同功能的现有代码并尽可能多地重用这些代码正逐渐成为程序员的一项关键软件开发活动[ 3]。代码检索的目标是根据给定的用户规范（例如，描述代码片段功能的短文本）从可用的开源存储库中检索特定的代码片段。实现这种代码检索系统的关键挑战在于两个方面：（a）对源代码的深入语义理解和（b）测量跨模态（即输入自然语言和源代码）的相似性。


**Existing Efforts and Limitations.** 为了搜索自然语言查询的大量可用代码资源，已经做出了许多现有的努力，范围从关键字匹配 [4, 5] 到语义检索 [3, 6]。 Lu等人[4]使用从WordNet获得的同义词扩展查询，然后对方法签名进行关键字匹配。 Lv 等人 [5] 使用 API 扩展了查询，并考虑了文本相似性和潜在 API 对代码搜索的影响。 Reiss等人[3]开发了一种名为Sourcerer的代码检索系统，该系统通过概率主题模型学习源代码的语义表示。受深度学习在计算机视觉和自然语言处理任务中成功的启发，深度学习已被应用于更好地表示克隆检测[7]和代码摘要[8]等任务的源代码。

据我们所知，Gu 等人。 al., [6] 是第一个将深度学习网络应用于代码检索任务的人，它捕获中间语义空间中语义源代码和自然语言查询之间的相关性。然而，该方法仍然存在两个主要局限性：（a）源代码的深层结构化特征经常被忽略。该方法[6]捕获了浅层源代码信息，包括方法名称、代码标记和API序列，错过了捕获代码丰富的结构语义的机会。 (b) 缺乏可解释性。深度神经网络的最终结果通常很难解释，因为其内部工作对于输入数据和不同的应用程序始终是透明的。这也是应用深度学习模型时的常见问题。例如，在[6]中，代码及其自然语言描述被投影到中间语义空间中，并受到排名损失函数的约束。尽管学习了代码的语义表示，但很难推断哪些部分对最终结果贡献更大。


**Insights.** 上述这些限制促使我们设计一个模型，该模型可以学习源代码的更全面的表示以及可解释性的能力。一方面，对于**限制（a）**，除了代码的标记之外，我们还从代码的多个视图中提取更多的代码特征，例如抽象语法树（AST）和控制流图（CFG）$^1$ 。AST和CFG是两种类型的中间代码，其中一种代表程序的层次语法结构，另一种代表程序的计算和控制流程[9]。在本文中，**我们认为从源代码的多个视图聚合补充信息可以丰富其表示。** 在本文中，我们交替使用术语“视图”和“模态”。我们将从多种视图/模式中学习代码表示的方法称为多模式学习。为了解决**限制（b）**，因为不同的模式反映了源代码的不同特征。**因此，每种模态对最终代码表示的贡献可能不同**。对于给定的模态，它由许多元素（令牌、AST/CFG 中的节点）组成，通过表示学习将权重分配给不同的元素。因此，我们可以从最终的表示中推断出哪一部分对最终结果贡献更大，从而使可解释性成为可能。在本文中，我们设计了一种注意力机制，将多模态特征集成到单个混合代码表示中。


**A Motivating Example.** 我们**在图 1 中**给出了一个例子来更好地说明我们的想法。**图 1(a) 显示**了一个简单的 C 代码示例，旨在验证整数数组是否包含偶数。图 1(b) 和 (c) 分别表示图 1(a) 中代码的相应 AST 和过程间 CFG。从图1（a）中，我们可以看到突出显示的三个单词Verify、array、even的语义可以通过不同的代码表示来精确捕获，例如纯文本（用于检查）、类型增强的AST（用于BinaryOperator）和CFG（暂时）。**这些表示关注不同视图下代码的不同结构信息，例如 AST 上的每个节点代表一个 token，CFG 上的每个节点代表一个语句**。这表明有必要考虑各种模式以更好地表示源代码。有必要从多个视图，特别是从结构化信息来表示代码，因为根据不同的代码表示，两个视图上的标记和语句的顺序可能不同。例如，基于纯文本，图1(a)中“while”后面的标记是“()”，然后是“head”。**不同的是，在 AST 上**，“Compound”后面会有两个可能的标记，即分支测试“if”、“BinaryOperator”，**如图 1（b）所示**。同样，在第 6 行最后一个语句中的标记“}”之后，基于纯文本将不会留下任何标记。然而，基于CFG，下一个标记是基于CFG的循环函数开始处的“while”。**从图1中**我们还可以观察到代码片段之间存在对齐关系，并且是描述。例如，关键字“Verify”应与“check in code”一词紧密相连。 这意味着，在代码检索时，我们可以推断检索到的代码的哪一部分对输入查询词贡献最大。这对于模型的可解释性非常重要。

![alt text](image-1.png)

*图 1：一个激励示例，可以更好地说明我们的动机。 (a) 代码片段及其相应的描述。 (b) 代码片段的 AST。 (c) 代码片段的控制流图。*


**Our Solution and Contributions.** 为了解决上述两个问题，在本文中，我们提出了一种用于语义源代码检索的新模型，称为多模态注意网络（MMAN）。我们不仅考虑之前研究过的顺序特征（即方法名称和标记），还考虑结构特征（即从代码中提取的 AST 和 CFG）。我们探索了一种新颖的多模态神经网络来有效地同时捕获这些多模态特征。特别是，**我们使用 LSTM [10] 来表示代码片段的顺序标记，使用 Tree-LSTM [11] 网络来表示抽象语法树（AST），并使用门控图神经网络（GGNN）[12] 来表示CFG**。为了克服可解释性问题，我们设计了一种注意力机制，为源代码每种模态的不同部分分配不同的权重，并具有解释能力。总而言之，本文的主要贡献如下。

- 我们提出了一种**更全面的源代码多模态表示方法**，其中一个LSTM 用于源代码的顺序内容，一个Tree-LSTM 用于源代码的AST，一个GGNN 用于源代码的CFG。此外，应用多模态融合层来集成这三种表示。
- 据我们所知，这是我们第一次**提出一个注意力网络来为源代码的每种模态的不同部分分配不同的权重**，从而为我们的深度多模态神经网络的表示提供了可解释性。
- 为了验证我们提出的模型的有效性，我们在从 GitHub 爬取的真实数据集上验证了我们提出的模型，该数据集由 28,527 个 C 代码片段组成。综合实验和分析表明，与一些最先进的方法相比，我们提出的模型是有效的。


**Organization.** 本文的其余部分安排如下。第二部分重点介绍了与本文相关的一些工作。在第三节中，我们提供了一些有关多模式学习和注意力机制的背景知识。**在第四节中，我们首先概述我们提出的框架，然后详细介绍我们提出的框架的每个模块**。第五节描述了我们实验中使用的数据集并显示了实验结果和分析。第六节对我们提出的模型进行了讨论，包括我们模型的优势以及对有效性的一些威胁和局限性。最后，我们总结本文并在第七节给出一些未来的研究方向。



<br>
<br>
<br>


### 2. Related Work 
在本节中，我们从深度代码表示、多模态学习和注意力机制三个角度简要回顾相关研究。

<br>
<br>

#### 2.1 Deep Code Representation
随着深度学习的成功发展，在软件工程研究领域中表示源代码也变得越来越普遍。在[13]中，Mou 等人。使用树结构卷积神经网络 (Tree-CNN) 学习分布式向量表示，以表示程序分类的代码片段。同样，Wan 等人。 **[8]应用树结构递归神经网络（Tree-LSTM）来表示源代码的AST以完成代码摘要任务**。皮耶希等人。 [14] 和帕里索托等人。 [15]学习源代码输入/输出对的分布式表示，并使用它们来指导示例中的程序合成。在[12]中，Li等人。将堆状态表示为图，并提出了门控图神经网络来直接学习其表示，以数学方式描述堆的形状。 Maddison 和 Tarlow [16] 以及其他神经语言模型（例如 Dam 等人 [17] 中的 LSTM）描述了上下文分布式表示，同时顺序生成代码。凌等人。 [18] 和 Allamanis 等人。 [19]将代码上下文分布式表示与其他模态（例如自然语言）的分布式表示相结合来合成代码。

上述方法的一个局限性是这些方法忽略了源代码的CFG，而源代码也传达了丰富的语义信息。此外，没有提出统一的网络来有效地融合这些多种模式。为了缓解这个问题，本文提出了一种多模态网络来学习更全面的源代码表示。

<br>
<br>

#### 2.2 Multi-Modal Learning
多模态学习的一个流行方向是**联合表示**，它已应用于许多应用，例如图像字幕[20]、摘要[21]、视觉问答[22]和对话系统[23]。在[20]中，陈等人。提出一种注意力分层神经网络来同时总结文本文档及其随附图像。在[21]中，Zhang等人。提出一种多模式（即产品的图像和长描述）生成对抗网络，用于移动电子商务中的产品标题细化。在[22]中，Kim 等人。提出一个双重注意网络，通过学习视频输入的潜在变量（即帧和字幕）来捕获完整视频内容的高级抽象。类似地，在[23]中，Hori 等人。使用学习的音频特征、图像特征和视频描述回答有关图像的问题，用于视听场景感知对话。**多模态学习的另一个方向是用于信息检索的跨模态表示学习**，这与我们的任务类似。**跨模态表示学习旨在通过将每种模态的表示投影到具有约束的中间语义空间来学习每种模态的表示**。在[24]中，Carvalho 等人。提出一种跨模式检索模型，在共享表示空间中对齐视觉和文本数据（例如菜肴及其食谱的图片）以进行收据检索。在[25]Ma等人中。提出了一种用于跨模态检索的神经架构，它结合了一个用于图像表示的 CNN 和一个用于计算图像和句子之间的单词级、短语级和句子级匹配分数的 CNN。 [26, 27]，作者学习了哈希函数，将原始空间中的图像和文本映射到二进制代码的汉明空间中，使得原始空间中的对象之间的相似性保留在汉明空间中。

在本文中，我们从多模态学习中汲取见解，但不仅限于此。我们不仅设计了一个多模态神经网络来表示代码，还应用了注意力机制来学习代码的哪一部分对最终语义表示贡献更大。


<br>
<br>


#### 2.3 Attention Mechanism
注意力机制在神经机器翻译[28]、图像字幕[29]、图像分类[30]和视觉问答[31]等许多人工智能领域取得了显着的成功。注意力机制允许模型在任务的每个步骤中关注视觉或文本输入的必要部分。视觉注意力模型有选择地关注图像中的小区域以提取核心特征并减少要处理的信息量。最近，许多方法采用视觉注意力来有益于图像分类 [32, 33]、图像生成 [34]、图像字幕 [35]、视觉问答 [36, 37, 38] 等。注意机制通常旨在在编码器-解码器框架下找到语义或句法输入输出对齐，这在处理长期依赖方面特别有效。这种方法已成功应用于各种任务，包括机器翻译 [28]、文本生成 [39]、句子摘要 [8, 40] 和问答 [41]。在[31]中，Lu等人。提出一个共同注意学习框架，交替学习视觉问答的图像注意和问题注意。在[42]中，Nam 等人。提出了一个多阶段共同注意力学习框架，以基于先前注意力的记忆来细化注意力。在[43]中，保卢斯等人。在深度强化学习设置中结合内部和内部注意机制，以提高抽象文本摘要的性能。在[44]中，Zhang等人。将自注意力机制引入卷积生成对抗网络。

据我们所知，还没有研究尝试学习用于代码检索任务的多模态注意力模型。


<br>
<br>
<br>


### 3. Preliminaries
在本节中，我们首先使用一些基本符号和术语在数学上形式化代码检索问题。然后我们介绍多模态学习和注意力机制的一些背景知识。

<br>
<br>

#### 3.1 Problem Formulation
